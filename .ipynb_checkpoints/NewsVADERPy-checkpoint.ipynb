{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Explanation\n",
    "\n",
    "In this assignment, you'll create a Python script to perform a sentiment analysis of the Twitter activity of various news oulets, and to present your findings visually.\n",
    "\n",
    "Your final output should provide a visualized summary of the sentiments expressed in the last 100 Tweets sent out by the following news organizations: __BBC, CBS, CNN, Fox, and New York times__.\n",
    "\n",
    "Your final Jupyter notebook must:\n",
    "\n",
    "* Pull last 100 tweets from each outlet.\n",
    "* Perform a sentiment analysis with the compound, positive, neutral, and negative scoring for each tweet. \n",
    "* Pull into a DataFrame the tweet's source acount, its text, its date, and its compound, positive, neutral, and negative sentiment scores.\n",
    "* Export the data in the DataFrame into a CSV file.\n",
    "* Save PNG images for each plot.\n",
    "\n",
    "As final considerations:\n",
    "\n",
    "* Use the Matplotlib and Seaborn libraries.\n",
    "* Include a written description of three observable trends based on the data. \n",
    "* Include proper labeling of your plots, including plot titles (with date of analysis) and axes labels.\n",
    "* Include an exported markdown version of your Notebook called  `README.md` in your GitHub repository.  \n",
    "\n",
    "\n",
    "Hints, requirements, and considerations:\n",
    "\n",
    "* You may find it helpful to organize your code in function(s), then call them.\n",
    "* If you're not yet familiar with creating functions in Python, here is a tutorial you may wish to consult: [https://www.tutorialspoint.com/python/python_functions.htm](https://www.tutorialspoint.com/python/python_functions.htm).\n",
    "\n",
    "\n",
    "\n",
    "## Copyright\n",
    "\n",
    "Coding Boot Camp (C) 2017. All Rights Reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NewsVADERPy: News Mood Analysis\n",
    "\n",
    "- Trend 1\n",
    "- Trend 2\n",
    "- Trend 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# Step 1: Import necessary modules and environment (which contains\n",
    "# Twitter API keys) and set up Twitter API authentication and the VADER\n",
    "# Sentiment Analyzer\n",
    "# ----------------------------------------------------------------------\n",
    "# import libraries\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tweepy\n",
    "\n",
    "# import environment, then import API keys from environment\n",
    "import os\n",
    "consumer_key = os.environ['twitter_consumer_key']\n",
    "consumer_secret = os.environ['twitter_consumer_secret']\n",
    "access_token = os.environ['twitter_access_token']\n",
    "access_token_secret = os.environ['twitter_access_token_secret']\n",
    "\n",
    "# import + initialize VADER\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# Step 2: Create function to parse and clean tweet data and return \n",
    "# sentiment information based on VADER\n",
    "# ----------------------------------------------------------------------\n",
    "def parseTweet(handle,numTweets):\n",
    "    \"\"\"\n",
    "    This function takes in two arguments:\n",
    "        1) Twitter handle (String), and \n",
    "        2) the number of (most recent) tweets you want analyzed. (int) \n",
    "    \n",
    "    It returns a dictionary with the following key:value pairs:\n",
    "        - \"handle\":\"handle\" (str)\n",
    "        - \"compound\":value (float)\n",
    "        - \"positive\":value (float)\n",
    "        - \"neutral\":value (float)\n",
    "        - \"negative\":value (float)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Variables for holding results\n",
    "    compound_list = []\n",
    "    positive_list = []\n",
    "    negative_list = []\n",
    "    neutral_list = []\n",
    "    oldest_tweet = None   \n",
    "    \n",
    "    # Generate usable count of increment of 10 based on num tweets\n",
    "    numCycles = int(round(numTweets/10))\n",
    "    \n",
    "    # iterate the necessary number of times to get the requested numTweets\n",
    "    for i in range(numCycles):\n",
    "        # get a set of tweets, then increment max id so no double-counting\n",
    "        tweet_list = api.user_timeline(f\"@{handle}\", count=10, \n",
    "                                       max_id=oldest_tweet)\n",
    "        \n",
    "        \n",
    "        \n",
    "    #return {\"handle\":handle, \n",
    "    #        \"compound\":compound_list,\n",
    "    #        \"positive\":positive_list, \n",
    "    #        \"neutral\":neutral_list, \n",
    "    #        \"negative\":negative_list}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# Step 3: Call API, get tweets, and parse tweets into a dataframe+CSV\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# create list of target news organizations' Twitter handles\n",
    "targetNewsOrg_list = [\"BBC\", \"nytimes\", \"CNN\", \"FoxNews\", \n",
    "                      \"CBSNews\",\"NPR\", \"AP\", \"USATODAY\", \n",
    "                      \"NBCNews\", \"BreitbartNews\"]\n",
    "\n",
    "# define number of tweets we want to pull from each org\n",
    "numTweets = 10\n",
    "\n",
    "# create list to store dictionaries generated during analysis\n",
    "results_list = []\n",
    "\n",
    "# loop through each organization in the list\n",
    "#for i in range(len(targetNewsOrg_list)):\n",
    "    \n",
    "    #result = parseTweet(targetNewsOrg_list[i],numTweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first plot will be and/or feature the following:\n",
    "\n",
    "- Be a scatter plot of sentiments of the last 100 tweets sent out by each news organization, ranging from -1.0 to 1.0, where a score of 0 expresses a neutral sentiment, -1 the most negative sentiment possible, and +1 the most positive sentiment possible.\n",
    "- Each plot point will reflect the compound sentiment of a tweet.\n",
    "- Sort each plot point by its relative timestamp.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# Step 4: Generate first plot: scatterplot of last 100 tweets showing \n",
    "# compound sentiment and sorted by relative timestamp\n",
    "# ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bar plot visualizing the overall sentiments of the last 100 tweets from each organization. \n",
    "For this plot, you will again aggregate the compound sentiments analyzed by VADER.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# Step 5: Generate second plot: bar plot showing overall compound \n",
    "# sentiment in the last 100 tweets\n",
    "# ----------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
