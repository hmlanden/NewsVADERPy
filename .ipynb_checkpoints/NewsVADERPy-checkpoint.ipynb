{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment Explanation\n",
    "\n",
    "In this assignment, you'll create a Python script to perform a sentiment analysis of the Twitter activity of various news oulets, and to present your findings visually.\n",
    "\n",
    "Your final output should provide a visualized summary of the sentiments expressed in the last 100 Tweets sent out by the following news organizations: __BBC, CBS, CNN, Fox, and New York times__.\n",
    "\n",
    "Your final Jupyter notebook must:\n",
    "\n",
    "* Pull last 100 tweets from each outlet.\n",
    "* Perform a sentiment analysis with the compound, positive, neutral, and negative scoring for each tweet. \n",
    "* Pull into a DataFrame the tweet's source acount, its text, its date, and its compound, positive, neutral, and negative sentiment scores.\n",
    "* Export the data in the DataFrame into a CSV file.\n",
    "* Save PNG images for each plot.\n",
    "\n",
    "As final considerations:\n",
    "\n",
    "* Use the Matplotlib and Seaborn libraries.\n",
    "* Include a written description of three observable trends based on the data. \n",
    "* Include proper labeling of your plots, including plot titles (with date of analysis) and axes labels.\n",
    "* Include an exported markdown version of your Notebook called  `README.md` in your GitHub repository.  \n",
    "\n",
    "\n",
    "Hints, requirements, and considerations:\n",
    "\n",
    "* You may find it helpful to organize your code in function(s), then call them.\n",
    "* If you're not yet familiar with creating functions in Python, here is a tutorial you may wish to consult: [https://www.tutorialspoint.com/python/python_functions.htm](https://www.tutorialspoint.com/python/python_functions.htm).\n",
    "\n",
    "\n",
    "\n",
    "## Copyright\n",
    "\n",
    "Coding Boot Camp (C) 2017. All Rights Reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NewsVADERPy: News Mood Analysis\n",
    "\n",
    "- Trend 1\n",
    "- Trend 2\n",
    "- Trend 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# Step 1: Import necessary modules and environment (which contains\n",
    "# Twitter API keys) and set up Twitter API authentication and the VADER\n",
    "# Sentiment Analyzer\n",
    "# ----------------------------------------------------------------------\n",
    "# import libraries\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tweepy\n",
    "\n",
    "# import environment, then import API keys from environment\n",
    "import os\n",
    "consumer_key = os.environ['twitter_consumer_key']\n",
    "consumer_secret = os.environ['twitter_consumer_secret']\n",
    "access_token = os.environ['twitter_access_token']\n",
    "access_token_secret = os.environ['twitter_access_token_secret']\n",
    "\n",
    "# import + initialize VADER\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# Step 2: Create function to parse and clean tweet data and return \n",
    "# sentiment information based on VADER\n",
    "# ----------------------------------------------------------------------\n",
    "def parseTweets(targetNewsOrg_list,numTweets):\n",
    "    \"\"\"\n",
    "    This function takes in two arguments:\n",
    "        1) Twitter handle (String), and \n",
    "        2) the number of (most recent) tweets you want analyzed. (int) \n",
    "    \n",
    "    It returns a  list of dictionaries with the following key:value \n",
    "    pairs for each tweet:\n",
    "        - \"handle\":\"handle\" (str)\n",
    "        - \"date\":timestamp\n",
    "        - \"compound\":value (float)\n",
    "        - \"positive\":value (float)\n",
    "        - \"neutral\":value (float)\n",
    "        - \"negative\":value (float)\n",
    "    \"\"\"\n",
    "    # variable to store oldest tweet\n",
    "    oldest_tweet = None   \n",
    "    \n",
    "    # create an empty list to store dictionaries\n",
    "    results_list = []\n",
    "   \n",
    "    # ----------------------------------------------------------------------\n",
    "    # Step 2.5: \n",
    "    # - Iterate in increments of 10 until you get full numTweets.\n",
    "    # - For each set of 10:\n",
    "    #   - iterate through, \n",
    "    #   - analyze with VADER, then \n",
    "    #   - add to lists. \n",
    "    # ----------------------------------------------------------------------\n",
    "    \n",
    "    # loop through each organization in the list to pull tweets\n",
    "    for i in range(len(targetNewsOrg_list)):\n",
    "        # select the current news org from the list\n",
    "        handle = targetNewsOrg_list[i]\n",
    "        \n",
    "        # iterate the necessary number of times to get the requested numTweets\n",
    "        for i in range(numTweets):\n",
    "            # get list of tweets, then increment max id so no double-counting\n",
    "            try:\n",
    "                tweet_list = api.user_timeline(f\"@{handle}\", count=10, max_id=oldest_tweet)\n",
    "            except Exception:\n",
    "                raise\n",
    "        \n",
    "            # iterate over each tweet in the list to run analysis\n",
    "            tweetAnalysis = analyzer.polarity_scores(tweet_list[i]['text'])\n",
    "            \n",
    "            # add dictionary holding results to results list\n",
    "            results_list.append({\"handle\":handle,\"date\":tweet_list[i]['created_at'], \"compound\":tweetAnalysis['compound'],\"positive\":tweetAnalysis['pos'],\"neutral\":tweetAnalysis['neu'],\"negative\":tweetAnalysis['neg']})\n",
    "        \n",
    "        # reduce max id by one so it doesn't skip a tweet next round\n",
    "        oldest_tweet = int(tweet_list[i]['id_str']) - 1\n",
    "    \n",
    "    return pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound</th>\n",
       "      <th>date</th>\n",
       "      <th>handle</th>\n",
       "      <th>negative</th>\n",
       "      <th>neutral</th>\n",
       "      <th>positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4019</td>\n",
       "      <td>Sun Mar 04 20:11:35 +0000 2018</td>\n",
       "      <td>BBC</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8468</td>\n",
       "      <td>Sun Mar 04 19:00:05 +0000 2018</td>\n",
       "      <td>BBC</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.614</td>\n",
       "      <td>0.386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.4215</td>\n",
       "      <td>Sun Mar 04 18:59:39 +0000 2018</td>\n",
       "      <td>BBC</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.3182</td>\n",
       "      <td>Sun Mar 04 18:00:09 +0000 2018</td>\n",
       "      <td>BBC</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.901</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.4588</td>\n",
       "      <td>Sun Mar 04 16:57:46 +0000 2018</td>\n",
       "      <td>BBC</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6369</td>\n",
       "      <td>Sun Mar 04 16:30:12 +0000 2018</td>\n",
       "      <td>BBC</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.3382</td>\n",
       "      <td>Sun Mar 04 15:30:29 +0000 2018</td>\n",
       "      <td>BBC</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.1779</td>\n",
       "      <td>Sun Mar 04 15:00:06 +0000 2018</td>\n",
       "      <td>BBC</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0498</td>\n",
       "      <td>Sun Mar 04 14:03:03 +0000 2018</td>\n",
       "      <td>BBC</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.8020</td>\n",
       "      <td>Sun Mar 04 13:46:48 +0000 2018</td>\n",
       "      <td>BBC</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.702</td>\n",
       "      <td>0.298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>Sun Mar 04 13:30:13 +0000 2018</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.2500</td>\n",
       "      <td>Sun Mar 04 13:30:01 +0000 2018</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.5994</td>\n",
       "      <td>Sun Mar 04 13:00:07 +0000 2018</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.253</td>\n",
       "      <td>0.642</td>\n",
       "      <td>0.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.1531</td>\n",
       "      <td>Sun Mar 04 12:30:57 +0000 2018</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.4019</td>\n",
       "      <td>Sun Mar 04 12:00:21 +0000 2018</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.787</td>\n",
       "      <td>0.213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>Sun Mar 04 11:31:03 +0000 2018</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.6124</td>\n",
       "      <td>Sun Mar 04 11:00:35 +0000 2018</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.3612</td>\n",
       "      <td>Sun Mar 04 10:35:04 +0000 2018</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.762</td>\n",
       "      <td>0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.4019</td>\n",
       "      <td>Sun Mar 04 10:00:25 +0000 2018</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.863</td>\n",
       "      <td>0.137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>Sun Mar 04 09:51:56 +0000 2018</td>\n",
       "      <td>CNN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    compound                            date handle  negative  neutral  \\\n",
       "0     0.4019  Sun Mar 04 20:11:35 +0000 2018    BBC     0.089    0.726   \n",
       "1     0.8468  Sun Mar 04 19:00:05 +0000 2018    BBC     0.000    0.614   \n",
       "2     0.4215  Sun Mar 04 18:59:39 +0000 2018    BBC     0.000    0.882   \n",
       "3    -0.3182  Sun Mar 04 18:00:09 +0000 2018    BBC     0.099    0.901   \n",
       "4     0.4588  Sun Mar 04 16:57:46 +0000 2018    BBC     0.000    0.889   \n",
       "5     0.6369  Sun Mar 04 16:30:12 +0000 2018    BBC     0.000    0.811   \n",
       "6     0.3382  Sun Mar 04 15:30:29 +0000 2018    BBC     0.000    0.870   \n",
       "7     0.1779  Sun Mar 04 15:00:06 +0000 2018    BBC     0.000    0.876   \n",
       "8     0.0498  Sun Mar 04 14:03:03 +0000 2018    BBC     0.170    0.650   \n",
       "9     0.8020  Sun Mar 04 13:46:48 +0000 2018    BBC     0.000    0.702   \n",
       "10    0.0000  Sun Mar 04 13:30:13 +0000 2018    CNN     0.000    1.000   \n",
       "11    0.2500  Sun Mar 04 13:30:01 +0000 2018    CNN     0.000    0.864   \n",
       "12   -0.5994  Sun Mar 04 13:00:07 +0000 2018    CNN     0.253    0.642   \n",
       "13    0.1531  Sun Mar 04 12:30:57 +0000 2018    CNN     0.108    0.760   \n",
       "14    0.4019  Sun Mar 04 12:00:21 +0000 2018    CNN     0.000    0.787   \n",
       "15    0.0000  Sun Mar 04 11:31:03 +0000 2018    CNN     0.000    1.000   \n",
       "16   -0.6124  Sun Mar 04 11:00:35 +0000 2018    CNN     0.190    0.810   \n",
       "17    0.3612  Sun Mar 04 10:35:04 +0000 2018    CNN     0.000    0.762   \n",
       "18    0.4019  Sun Mar 04 10:00:25 +0000 2018    CNN     0.000    0.863   \n",
       "19    0.0000  Sun Mar 04 09:51:56 +0000 2018    CNN     0.000    1.000   \n",
       "\n",
       "    positive  \n",
       "0      0.184  \n",
       "1      0.386  \n",
       "2      0.118  \n",
       "3      0.000  \n",
       "4      0.111  \n",
       "5      0.189  \n",
       "6      0.130  \n",
       "7      0.124  \n",
       "8      0.180  \n",
       "9      0.298  \n",
       "10     0.000  \n",
       "11     0.136  \n",
       "12     0.106  \n",
       "13     0.132  \n",
       "14     0.213  \n",
       "15     0.000  \n",
       "16     0.000  \n",
       "17     0.238  \n",
       "18     0.137  \n",
       "19     0.000  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# Step 3: Call API, get tweets, and parse tweets into a dataframe+CSV\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# create list of target news organizations' Twitter handles\n",
    "targetNewsOrg_list = [\"BBC\",\"CNN\"]\n",
    "\n",
    "# define number of tweets we want to pull from each org\n",
    "numTweets = 10\n",
    "\n",
    "# create dict to store dictionaries generated during analysis\n",
    "completeResults_df = parseTweets(targetNewsOrg_list, numTweets)\n",
    "\n",
    "completeResults_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first plot will be and/or feature the following:\n",
    "\n",
    "- Be a scatter plot of sentiments of the last 100 tweets sent out by each news organization, ranging from -1.0 to 1.0, where a score of 0 expresses a neutral sentiment, -1 the most negative sentiment possible, and +1 the most positive sentiment possible.\n",
    "- Each plot point will reflect the compound sentiment of a tweet.\n",
    "- Sort each plot point by its relative timestamp.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# Step 4: Generate first plot: scatterplot of last 100 tweets showing \n",
    "# compound sentiment and sorted by relative timestamp\n",
    "# ----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bar plot visualizing the overall sentiments of the last 100 tweets from each organization. \n",
    "For this plot, you will again aggregate the compound sentiments analyzed by VADER.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ----------------------------------------------------------------------\n",
    "# Step 5: Generate second plot: bar plot showing overall compound \n",
    "# sentiment in the last 100 tweets\n",
    "# ----------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonData]",
   "language": "python",
   "name": "conda-env-PythonData-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
